# -*- coding: utf-8 -*-
"""DistractedDriverDetectionModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Iq8reWsQt-ClJlSxlXJeNSHuvE337Tcu
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras import Model
from keras.layers import Input, GlobalAveragePooling2D, BatchNormalization, Dropout, Dense
from tensorflow.keras.applications import EfficientNetB3
from tensorflow.keras.models import load_model
from keras.callbacks import ModelCheckpoint, EarlyStopping

from google.colab import drive
drive.mount('/content/drive')

base_dir = "/content/drive/MyDrive/D3MProject/d3m"
train_dir = os.path.join(base_dir, "/content/drive/MyDrive/D3MProject/d3m/imgs/train")
test_dir = os.path.join(base_dir, "/content/drive/MyDrive/D3MProject/d3m/imgs/test")

data = pd.read_csv(os.path.join(os.path.dirname(base_dir),"/content/drive/MyDrive/D3MProject/d3m/dimg.csv"))

data

data.head()

data.tail()

class_count = data.classname.value_counts()
fig = class_count.plot(kind = 'bar')

IMAGE_SIZE = (224,224)
BATCH_SIZE = 64

train_gen = ImageDataGenerator(
    width_shift_range = 0.3,
    height_shift_range = 0.3,
    shear_range = 0.3,
    zoom_range = 0.4,
    validation_split = 0.2)
test_gen = ImageDataGenerator()

train_data = train_gen.flow_from_directory(
    train_dir,
    target_size = IMAGE_SIZE,
    batch_size = BATCH_SIZE,
    seed = 42,
    subset = 'training'
)

val_data = train_gen.flow_from_directory(
    train_dir,
    target_size = IMAGE_SIZE,
    batch_size = BATCH_SIZE,
    seed = 42,
    subset = 'validation'
)

def define_model(num_classes):
    inputs = Input(shape = (224,224,3))
    base_model = EfficientNetB3(include_top = False, weights = 'imagenet')(inputs)
    x = GlobalAveragePooling2D()(base_model)
    x = BatchNormalization()(x)
    x = Dropout(0.2)(x)
    output = Dense(units = num_classes, activation = 'softmax')(x)
    model = Model(inputs = inputs, outputs = output)
    model.compile(optimizer = tf.optimizers.Adam(learning_rate = 1e-4),
                 loss = 'categorical_crossentropy',
                  metrics = ['accuracy'])
    return model

model = define_model(10)
model.summary()

checkpoint_callback = ModelCheckpoint('best_model.h5', save_best_only = True, monitor = 'val_loss', mode = 'min')
es = EarlyStopping(monitor = 'val_loss', patience = 5)

history = model.fit(train_data, epochs = 5, validation_data = val_data, callbacks = [es, checkpoint_callback])

test_dir = os.path.join(base_dir, 'imgs')
test_data = test_gen.flow_from_directory(
    test_dir,
    shuffle = False,
    target_size = IMAGE_SIZE,
    classes = ['test'],
    batch_size = BATCH_SIZE
)

models = "./best_model.h5"
if os.path.exists(models):
    model.load_weights(models)

preds = model.predict(test_data)

preds

df = pd.DataFrame(preds).T
df.to_excel(excel_writer = "/content/drive/MyDrive/D3MProject/d3m/test.xlsx")